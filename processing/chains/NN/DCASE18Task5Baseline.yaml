constants:
  CLASS_COUNT: 10
  CHANNELS:  NaN
  FEATURE_VECTOR_LENGTH: NaN
  INPUT_SEQUENCE_LENGTH: NaN
  CONVOLUTION_BORDER_MODE: valid
  ACTIVATION: relu
  DROPOUT: 0.2
  DENSE_UNITS: 64
  S: NaN # word size

chain:
  # Conv layer
  - layer_name: Conv2D
    config:
      input_shape: [CHANNELS, FEATURE_VECTOR_LENGTH, INPUT_SEQUENCE_LENGTH] # [channel, data, time]
      filters: 32
      kernel_size: [FEATURE_VECTOR_LENGTH, 5]
      strides: [1,1]
      padding: CONVOLUTION_BORDER_MODE
      use_bias: 1
    memory: {parameters: 1, output: 1, output_save: True}
    wordsize: S
  # Batch normalization
  - layer_name: BatchNormalization
    config:
      axis: 1 # data_axis
    memory: {parameters: 1, output: 1, output_save: False}
    wordsize: S
  # Detection layer
  - layer_name: Activation
    config:
      activation: ACTIVATION
    memory: {parameters: 1, output: 1, output_save: False}
    wordsize: S
  # Pooling layer
  - layer_name: MaxPooling2D
    config:
      pool_size: [1, 5]
      strides: [1, 5]
    memory: {parameters: 1, output: 1, output_save: False}
    wordsize: S
  # Drop out layer
  - layer_name: Dropout
    config:
      rate: DROPOUT
    memory: {parameters: 1, output: 1, output_save: False}
    wordsize: S
  # Conv. layer 
  - layer_name: Conv2D
    config:
      filters: 64
      kernel_size: [1,3]
      strides: [1,1]
      padding: CONVOLUTION_BORDER_MODE
      use_bias: 1
    memory: {parameters: 1, output: 1, output_save: True}
    wordsize: S
  # Batch normalization
  - layer_name: BatchNormalization
    config:
      axis: 1 # data_axis
    memory: {parameters: 1, output: 1, output_save: False}
    wordsize: S
  # Detection layer
  - layer_name: Activation
    config:
      activation: ACTIVATION
    memory: {parameters: 1, output: 1, output_save: False}
    wordsize: S
  # Pooling layer
  - layer_name: GlobalMaxPooling2D
    memory: {parameters: 1, output: 1, output_save: False}
    wordsize: S
  # Drop out layer
  - layer_name: Dropout
    config:
      rate: DROPOUT
    memory: {parameters: 1, output: 1, output_save: False}
    wordsize: S
  # Fully connected layer
  - layer_name: Dense
    config:
      units: DENSE_UNITS
      activation: ACTIVATION
    memory: {parameters: 1, output: 1, output_save: True}
    wordsize: S
  # Drop out layer
  - layer_name: Dropout
    config:
      rate: DROPOUT
    memory: {parameters: 1, output: 1, output_save: False}
    wordsize: S
  # Output layer
  - layer_name: Dense
    config:
      units: CLASS_COUNT
      activation: softmax
    memory: {parameters: 1, output: 1, output_save: True}
    wordsize: S